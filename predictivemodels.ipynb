{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this report is to implement and evaluate several alternative predictive models to predict whether an existing customer would be interested or not in Vehicle Insurance with the help of the predictors: Gender, Age, Driving License, Region Code, Previously Insured, Vehicle Age, Vehicle Damage, Annual Premium, Policy Sales Channel and Vintage.\n",
    "\n",
    "The data preprocessing have already been done in the datavisualization-preprocessing report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the required libraries are imported\n",
    "import numpy as np           #for efficient numerical operations\n",
    "import pandas as pd          #for manipulating and visualising data\n",
    "\n",
    "import time                  #for getting local time from the number of seconds elapsed\n",
    "\n",
    "import seaborn as sns             #for data visualization\n",
    "\n",
    "#load the required train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Age_log</th>\n",
       "      <th>Annual_Premium_log</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-1.197614</td>\n",
       "      <td>-0.956976</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>1.022372</td>\n",
       "      <td>0.228267</td>\n",
       "      <td>0.210398</td>\n",
       "      <td>0.871617</td>\n",
       "      <td>-0.345003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.074513</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-0.654205</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.747745</td>\n",
       "      <td>-0.852524</td>\n",
       "      <td>-0.785843</td>\n",
       "      <td>-0.331879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-0.654205</td>\n",
       "      <td>-0.956976</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>1.022372</td>\n",
       "      <td>-1.589904</td>\n",
       "      <td>-1.461615</td>\n",
       "      <td>0.489337</td>\n",
       "      <td>-0.459352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-1.818652</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.896167</td>\n",
       "      <td>-0.780867</td>\n",
       "      <td>-0.785843</td>\n",
       "      <td>-1.036554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.074513</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-1.896282</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.747745</td>\n",
       "      <td>-1.354128</td>\n",
       "      <td>-0.598007</td>\n",
       "      <td>1.223449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Driving_License  Region_Code  Previously_Insured  Vehicle_Age  \\\n",
       "0  0.930654         0.047053    -1.197614           -0.956976     0.724263   \n",
       "1 -1.074513         0.047053    -0.654205            1.044959    -1.025121   \n",
       "2  0.930654         0.047053    -0.654205           -0.956976     0.724263   \n",
       "3  0.930654         0.047053    -1.818652            1.044959    -1.025121   \n",
       "4 -1.074513         0.047053    -1.896282            1.044959    -1.025121   \n",
       "\n",
       "   Vehicle_Damage  Policy_Sales_Channel   Vintage   Age_log  \\\n",
       "0        1.022372              0.228267  0.210398  0.871617   \n",
       "1       -0.978117              0.747745 -0.852524 -0.785843   \n",
       "2        1.022372             -1.589904 -1.461615  0.489337   \n",
       "3       -0.978117              0.896167 -0.780867 -0.785843   \n",
       "4       -0.978117              0.747745 -1.354128 -0.598007   \n",
       "\n",
       "   Annual_Premium_log  Response  \n",
       "0           -0.345003         0  \n",
       "1           -0.331879         0  \n",
       "2           -0.459352         1  \n",
       "3           -1.036554         0  \n",
       "4            1.223449         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189674 entries, 0 to 189673\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Gender                189674 non-null  float64\n",
      " 1   Driving_License       189674 non-null  float64\n",
      " 2   Region_Code           189674 non-null  float64\n",
      " 3   Previously_Insured    189674 non-null  float64\n",
      " 4   Vehicle_Age           189674 non-null  float64\n",
      " 5   Vehicle_Damage        189674 non-null  float64\n",
      " 6   Policy_Sales_Channel  189674 non-null  float64\n",
      " 7   Vintage               189674 non-null  float64\n",
      " 8   Age_log               189674 non-null  float64\n",
      " 9   Annual_Premium_log    189674 non-null  float64\n",
      " 10  Response              189674 non-null  int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 15.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189674"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test dataset are too large and would take massive amounts of time to train models on this dataset. Therefore, a sample is taken out of the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling from train dataset\n",
    "ftrain = train.sample(n=50000, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Age_log</th>\n",
       "      <th>Annual_Premium_log</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50183</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-1.430503</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.729192</td>\n",
       "      <td>1.416637</td>\n",
       "      <td>-1.096595</td>\n",
       "      <td>0.815633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46028</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-1.430503</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.747745</td>\n",
       "      <td>-0.374806</td>\n",
       "      <td>-0.988722</td>\n",
       "      <td>2.021025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>-1.074513</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>0.587873</td>\n",
       "      <td>-0.956976</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.747745</td>\n",
       "      <td>0.735888</td>\n",
       "      <td>-0.509064</td>\n",
       "      <td>-0.685612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39742</th>\n",
       "      <td>-1.074513</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>0.122094</td>\n",
       "      <td>-0.956976</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>1.022372</td>\n",
       "      <td>-1.589904</td>\n",
       "      <td>0.819489</td>\n",
       "      <td>0.547607</td>\n",
       "      <td>2.429836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187634</th>\n",
       "      <td>0.930654</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>-0.343685</td>\n",
       "      <td>1.044959</td>\n",
       "      <td>-1.025121</td>\n",
       "      <td>-0.978117</td>\n",
       "      <td>0.896167</td>\n",
       "      <td>0.640345</td>\n",
       "      <td>-1.327174</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender  Driving_License  Region_Code  Previously_Insured  \\\n",
       "50183   0.930654         0.047053    -1.430503            1.044959   \n",
       "46028   0.930654         0.047053    -1.430503            1.044959   \n",
       "41101  -1.074513         0.047053     0.587873           -0.956976   \n",
       "39742  -1.074513         0.047053     0.122094           -0.956976   \n",
       "187634  0.930654         0.047053    -0.343685            1.044959   \n",
       "\n",
       "        Vehicle_Age  Vehicle_Damage  Policy_Sales_Channel   Vintage   Age_log  \\\n",
       "50183     -1.025121       -0.978117              0.729192  1.416637 -1.096595   \n",
       "46028     -1.025121       -0.978117              0.747745 -0.374806 -0.988722   \n",
       "41101     -1.025121       -0.978117              0.747745  0.735888 -0.509064   \n",
       "39742      0.724263        1.022372             -1.589904  0.819489  0.547607   \n",
       "187634    -1.025121       -0.978117              0.896167  0.640345 -1.327174   \n",
       "\n",
       "        Annual_Premium_log  Response  \n",
       "50183             0.815633         0  \n",
       "46028             2.021025         0  \n",
       "41101            -0.685612         0  \n",
       "39742             2.429836         1  \n",
       "187634            0.145065         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling from test dataset\n",
    "ftest = test.sample(n=35000, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Age_log</th>\n",
       "      <th>Annual_Premium_log</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140791</th>\n",
       "      <td>0.922772</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>0.122655</td>\n",
       "      <td>-0.919475</td>\n",
       "      <td>-1.074838</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.220503</td>\n",
       "      <td>-0.864108</td>\n",
       "      <td>-1.257842</td>\n",
       "      <td>-0.084741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21139</th>\n",
       "      <td>-1.083691</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>-1.161235</td>\n",
       "      <td>-0.919475</td>\n",
       "      <td>0.689124</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>-1.587009</td>\n",
       "      <td>1.170042</td>\n",
       "      <td>0.518490</td>\n",
       "      <td>1.032980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>-1.083691</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>-0.028391</td>\n",
       "      <td>1.087577</td>\n",
       "      <td>-1.074838</td>\n",
       "      <td>-1.008869</td>\n",
       "      <td>0.884487</td>\n",
       "      <td>-0.253863</td>\n",
       "      <td>-0.829732</td>\n",
       "      <td>-2.127575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13704</th>\n",
       "      <td>0.922772</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>1.482068</td>\n",
       "      <td>1.087577</td>\n",
       "      <td>-1.074838</td>\n",
       "      <td>-1.008869</td>\n",
       "      <td>0.884487</td>\n",
       "      <td>-0.026517</td>\n",
       "      <td>-1.377059</td>\n",
       "      <td>-0.049361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21554</th>\n",
       "      <td>0.922772</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>-0.406006</td>\n",
       "      <td>-0.919475</td>\n",
       "      <td>0.689124</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>-1.587009</td>\n",
       "      <td>-1.306835</td>\n",
       "      <td>0.896837</td>\n",
       "      <td>0.597470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender  Driving_License  Region_Code  Previously_Insured  \\\n",
       "140791  0.922772         0.045936     0.122655           -0.919475   \n",
       "21139  -1.083691         0.045936    -1.161235           -0.919475   \n",
       "12854  -1.083691         0.045936    -0.028391            1.087577   \n",
       "13704   0.922772         0.045936     1.482068            1.087577   \n",
       "21554   0.922772         0.045936    -0.406006           -0.919475   \n",
       "\n",
       "        Vehicle_Age  Vehicle_Damage  Policy_Sales_Channel   Vintage   Age_log  \\\n",
       "140791    -1.074838        0.991209              0.220503 -0.864108 -1.257842   \n",
       "21139      0.689124        0.991209             -1.587009  1.170042  0.518490   \n",
       "12854     -1.074838       -1.008869              0.884487 -0.253863 -0.829732   \n",
       "13704     -1.074838       -1.008869              0.884487 -0.026517 -1.377059   \n",
       "21554      0.689124        0.991209             -1.587009 -1.306835  0.896837   \n",
       "\n",
       "        Annual_Premium_log  Response  \n",
       "140791           -0.084741         1  \n",
       "21139             1.032980         1  \n",
       "12854            -2.127575         0  \n",
       "13704            -0.049361         0  \n",
       "21554             0.597470         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Models\n",
    "\n",
    "The first step is to create seperate arrays for the predictors (`Xtrain`) and for the target (`ytrain`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#seperating the predictors and target variable\n",
    "Xtrain = ftrain.drop('Response', axis=1)\n",
    "\n",
    "ytrain = ftrain['Response'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Baseline Model\n",
    "\n",
    "A majority class classifier is used as baseline where most common class label in the training set would be found out and predicted as the output always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43867\n",
       "1     6133\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the number of instances\n",
    "ftrain[\"Response\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Not interested, 1: Interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set size\n",
    "ftrain.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the baseline classifier, the output will be \"Not interested\" for all predictions. In this project, macro-averaging will be used (precision, recall and F-score are evaluated in each class seperately and then avergaed across classes).\n",
    "\n",
    "Therefore, applying the baseline classifier to all of the train dataset.\n",
    "\n",
    "For responses with \"Not interested\", the accuarcy measures will be:\n",
    "\n",
    " - Precision: 43867/50000 = 0.877\n",
    " - Recall: 50000/50000 = 1.0\n",
    " - F-score: 2/(1/precision+1/recall) = 0.935\n",
    " \n",
    "For responses with \"Interested\", the accuarcy measures will be:\n",
    "\n",
    " - Precision: 0.0/0.0 = 0.0\n",
    " - Recall: 0.0/6133 = 0.0\n",
    " - F-score: 0.0\n",
    " \n",
    "The averages of the two classes which is the eventual baseline scores, are:\n",
    "\n",
    " - Precision: 0.439\n",
    " - Recall: 0.5\n",
    " - F-score: 0.468"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 899.0751824378967 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#put in the hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 200, 1000],\n",
    "    'max_depth': [3, 5, 15],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "#5-fold cross-validation is used\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5,\n",
    "                          scoring='f1_macro',\n",
    "                          return_train_score=True)\n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_split=5, n_estimators=10,\n",
       "                       random_state=7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5077910772485159"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters prove to be n_estimators = 200, max_depth = 15 and min_sample_split=5. Based on this, they achieve a F-score of 0.51 which is the best one so far.\n",
    "\n",
    "The results of the best model are recorded in each split and the below command gives the index of the best performing model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_['rank_test_score'].tolist().index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_split_test_scores = []\n",
    "for x in range(5):\n",
    "    #extract f-score of the best model (index=18) from each of the 5 splits\n",
    "    val = grid_search.cv_results_[f\"split{x}_test_score\"][18]\n",
    "    rf_split_test_scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores achieved by all the models for different hyperparameter are reviewed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5077910772485159 0.6144937097675991 {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 10, 'random_state': 7}\n",
      "0.500160391905794 0.5800966185190405 {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 10, 'random_state': 7}\n",
      "0.4901043794684668 0.5983222542940497 {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 7}\n",
      "0.489769462731983 0.5974611399846733 {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 7}\n",
      "0.488091595400079 0.5962736744561885 {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.48802775984303126 0.565265257292125 {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 7}\n",
      "0.4879105683806045 0.5624624248068428 {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.487125083987973 0.5651251866402451 {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 10, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 10, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'random_state': 7}\n"
     ]
    }
   ],
   "source": [
    "val_scores = grid_search.cv_results_['mean_test_score']\n",
    "train_scores = grid_search.cv_results_['mean_train_score']\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Random Forest varies between 0.47 and 0.51. It can also be noticed that better score is achieved for greater max_depth. However, this score is only slight better than the baseline model. Therefore, more models need to evaluted for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle_Damage: 0.23034578200483757\n",
      "Age_log: 0.15910325280867196\n",
      "Annual_Premium_log: 0.1399068056819435\n",
      "Previously_Insured: 0.13163255776225508\n",
      "Vintage: 0.11583783732321544\n",
      "Policy_Sales_Channel: 0.08475334501851194\n",
      "Region_Code: 0.06984894911839537\n",
      "Vehicle_Age: 0.05473726453721193\n",
      "Gender: 0.012907136629646949\n",
      "Driving_License: 0.0009270691153103203\n"
     ]
    }
   ],
   "source": [
    "# put them into a separate variable for convenience\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "# the order of the features in `feature_importances` is the same as in the Xtrain dataframe,\n",
    "# so we can \"zip\" the two and print in the descending order:\n",
    "\n",
    "for k, v in sorted(zip(feature_importances, Xtrain.columns), reverse=True):\n",
    "    print(f\"{v}: {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vehicle damage, age, annual premium, previously insured and vintage are quite predictive of whether a customer would be interested in vehicle insurance or not.\n",
    "\n",
    "Every other variable has very little to do with the response of the customer.\n",
    "\n",
    "Following on, the model is saved to the disk so that it can be used in the future directly for testing instead of re-training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML models/rf-clf.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "#creating a folder to save all the models\n",
    "if not os.path.exists('ML models'):\n",
    "    os.makedirs('ML models')\n",
    "\n",
    "dump(grid_search.best_estimator_, 'ML models/rf-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be loaded later on using joblib's load function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.1. Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 498.01508927345276 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC()\n",
    "\n",
    "# specify the hypermaters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 3, 5],\n",
    "    'max_iter': [5000],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "#5-fold cross-validation is used\n",
    "grid_search = GridSearchCV(lsvm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, max_iter=5000, random_state=7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4673314366705239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant difference between the f-score of the Linear SVM and the baseline model. Therefore, this model turns out to be very poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4673314366705239 0.46733143701057855 {'C': 3, 'max_iter': 5000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'C': 1, 'max_iter': 5000, 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'C': 0.1, 'max_iter': 5000, 'random_state': 7}\n",
      "0.46732576201501475 0.4673662960221964 {'C': 5, 'max_iter': 5000, 'random_state': 7}\n"
     ]
    }
   ],
   "source": [
    "val_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it can be seen that there is no difference in the F-score as the C-value changes. \n",
    "\n",
    "However, this model is now saved for future refernece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML models/svm-lnr-clf.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"ML models\"):\n",
    "    os.makedirs(\"ML models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, 'ML models/svm-lnr-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.2. Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 5844.312863826752 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "#put in the parameters\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [\"scale\", \"auto\"],\n",
    "    'kernel': [\"rbf\"],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "#5-fold cross-validation is used\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model took significant number of hours to train and are impartical for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma='auto', random_state=7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4752675855876845"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-score of this model is approximately 0.475 which is 0.01 more than that of the baseline model. Therefore, this model turns out to be no better than the baseline model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the f-scores of the best models in each split\n",
    "\n",
    "svmrbf_split_test_scores = []\n",
    "for x in range(5):\n",
    "    # extract f-score of the best model (at index=0) from each of the 5 splits\n",
    "    val = grid_search.cv_results_[f\"split{x}_test_score\"][0]\n",
    "    svmrbf_split_test_scores.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4752675855876845 0.49304582093749144 {'C': 100, 'gamma': 'auto', 'kernel': 'rbf', 'random_state': 7}\n",
      "0.4749530799050228 0.49179605580100966 {'C': 100, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 7}\n",
      "0.4682958744065912 0.47032797495572937 {'C': 10, 'gamma': 'auto', 'kernel': 'rbf', 'random_state': 7}\n",
      "0.4682958744065912 0.470081072861702 {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 7}\n",
      "0.4673314366705239 0.46733143701057855 {'C': 1, 'gamma': 'auto', 'kernel': 'rbf', 'random_state': 7}\n"
     ]
    }
   ],
   "source": [
    "val_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it can be seen that the F-scores of the model increase with increase in the C - value. This is similar to that of random forests where high values of dept produced better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial SVM was ignored as it took significant hours to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM rbf model is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML models/svm-rbf-clf.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"ML models\"):\n",
    "    os.makedirs(\"ML models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, 'ML models/svm-rbf-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two SVM models above, the F-scores are less than what was observed for Random forest and are not significantly different from the baseline models. Compared to the SVM models, the random forest was slightly better with an F-score of 0.51. However, this is an extremly poor score as well in reality. A model with such poor score has significantly low prediction power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though, models that were trained have a poor f-score, the random forest with the relatively high f-score will be evaluated on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is loaded from the local disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "best_rf = load(\"ML models/rf-clf.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop labels for training set, but keep all others\n",
    "Xtest = ftest.drop(\"Response\", axis=1)\n",
    "ytest = ftest[\"Response\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Precision: 0.6461335174851621\n",
      "Recall: 0.5258023688231142\n",
      "F score: 0.5218418455618304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# rf\n",
    "yhat = best_rf.predict(Xtest)\n",
    "\n",
    "# micro-averaged precision, recall and f-score\n",
    "p, r, f, s = precision_recall_fscore_support(ytest, yhat, average=\"macro\")\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, similar classification accuracy can be found with Random forrest classifier, as observed during cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Future Improvements and Business Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is big room for future improvments for the model as the models accuracy is very poor. Different steps need to be taken to overcome this problem. One of the reason for this poor score could be that fact that there was significantly low number of customers interested in vehicle insurance compared to customers who weren't. This could have potentially created a bias in the models learning. Another problem is that the predictors may not be a good representative of the target variable. To support this, the correlation matrix in the group report showed very poor correlation between the target variable and the predictors. Addressing these problesm could be potential future improvements. \n",
    "\n",
    "Currently, this model cannot be used in real world scenarios due to its low accuarcy but similar models with high accuracy can be used in various business scenarios. For example, banks can use this type of model to predict who would be interested in a certain type of credit or debit cards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
